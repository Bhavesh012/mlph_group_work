{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1326.56103515625\n",
      "199 892.927001953125\n",
      "299 602.4588623046875\n",
      "399 407.74859619140625\n",
      "499 277.1295166015625\n",
      "599 189.4365692138672\n",
      "699 130.51473999023438\n",
      "799 90.89109802246094\n",
      "899 64.2218246459961\n",
      "999 46.25544738769531\n",
      "1099 34.14069747924805\n",
      "1199 25.96388053894043\n",
      "1299 20.439611434936523\n",
      "1399 16.703611373901367\n",
      "1499 14.174392700195312\n",
      "1599 12.46034049987793\n",
      "1699 11.29747200012207\n",
      "1799 10.50770092010498\n",
      "1899 9.970731735229492\n",
      "1999 9.605216979980469\n",
      "Result: y = 0.020772410556674004 + 0.837228000164032 x + -0.0035835853777825832 x^2 + -0.0905548706650734 x^3\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "# Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc('font', family='monospace', size=14, serif='courier')\n",
    "plt.rc('mathtext', fontset='stix')\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NN architecture.\n",
    "class MLPDeep(nn.Module):\n",
    "    def __init__(self,n=2,p=5,k=1):\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "        n : no. of inputs (dimensions)\n",
    "        p : no. of neurons in hidden layers\n",
    "        k : no. of nuerons in output layer\n",
    "        \"\"\"\n",
    "        super(MLPDeep,self).__init__()\n",
    "        # TODO: initialize Linear Layers and the activation as specified on the sheet  \n",
    "        self.multi_hidden = nn.Sequential(\n",
    "                            nn.Linear(n, p),        # hidden layer 1\n",
    "                            nn.ReLU(),                # relu\n",
    "                            nn.Linear(p, p),        # hidden layer 2\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(p, p),        # hidden layer 3\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(p, p),        # hidden layer 4\n",
    "                            nn.ReLU(),                                                                                 \n",
    "                            nn.Linear(p,k))        # output layer  \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: pass the input x through the layers and return the output\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "        x : input matrix\n",
    "        \"\"\"       \n",
    "        # TODO: pass the input x through the layers and return the outpu \n",
    "        y = self.multi_hidden(x)\n",
    "        return y\n",
    "\n",
    "def visualize_model(model, res=500, bound=5):\n",
    "    # TODO: implement a function that takes the model (the MLP), and builds a \n",
    "    #       grid of points in [-bound, bound] x [-bound, bound], passes them \n",
    "    #       through the model and returns the result in the shape of an image\n",
    "\n",
    "    #grids of points\n",
    "    x1 = np.linspace(-bound,bound,res)\n",
    "    x2 = np.linspace(-bound,bound,res)\n",
    "    x1v,x2v = np.meshgrid(x1,x2)                    \n",
    "\n",
    "    # genrating the input torch.tensor \n",
    "    x = np.stack((x1v.ravel(),x2v.ravel()),axis=1)   \n",
    "    x = torch.from_numpy(x).to(torch.float32)\n",
    "\n",
    "    # passing through model\n",
    "    y = model(x).to(device=torch.device(\"mps\"))                                \n",
    "    \n",
    "    return y.cpu().detach().numpy().reshape(res,res)      #reshaping the output vector into the shape of an image\n",
    "\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "# TODO: repeat the visualizations from above\n",
    "model_deep = MLPDeep(2,5,1)\n",
    "# model_deep = torch.compile(model_deep)\n",
    "bounds = [5,10,10,500,1000]\n",
    "img = [visualize_model(model_deep,res=1000, bound=bound) for bound in bounds]\n",
    "\n",
    "# plotting the model outputs for different ranges\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.suptitle('Deep Learning Model: Range comparison', fontsize=20, y=0.99)\n",
    "plt.tight_layout()\n",
    "#setting no. of rows and columns for subplot\n",
    "ncols = 3\n",
    "nrows = len(img) // ncols + (len(img) % ncols > 0) # calculating number of rows\n",
    "\n",
    "for n,im in enumerate(img):\n",
    "    #adding subplot iteratively\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    ax.imshow(im,origin='lower')\n",
    "    ax.set_title(f'range: {-bounds[n],bounds[n]}')\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ffdc53052217594773f6665aec6e115f8cc169cdd66db1aff02556edad0c31d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
